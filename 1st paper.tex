\documentclass[12pt]{article}
\usepackage{jcappub}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage[normalem]{ulem}
\usepackage{mathtools} %For summations with limits
\usepackage{multicol} %For multiple columns
\setlength{\columnsep}{1cm}


\title{The Distribution of Vacua in Random Landscape Potentials}

\author{Low Lerh Feng,}
\author{Shaun Hotchkiss}
\author{and Richard Easther}

\emailAdd{lerh.low@auckland.ac.nz}
\emailAdd{s.hotchkiss@auckland.ac.nz}
\emailAdd{r.easther@auckland.ac.nz}

\newcommand{\re}[1]{\textcolor{blue}{[{\bf RE}: #1]}}
\newcommand{\lfl}[1]{\textcolor{red}{[{\bf LL}: #1]}}
\newcommand{\SH}[1]{\textcolor{brown}{[{\bf SH}: #1]}}
\newcommand{\sh}[1]{\textcolor{brown}{#1}}
\newcommand{\LFL}[1]{\textcolor{red}{#1}}


\affiliation{Department of Physics,\\ University of Auckland, \\Private Bag 92019,\\ Auckland, New Zealand}

\abstract{ Landscape cosmology posits the existence of a convoluted, multidimensional, scalar potential -- the  ``landscape'' -- with vast numbers of metastable minima, motivating arguments that landscape cosmology provides a framework in which anthropic or ``environmental'' selection is plausible. Random matrices and random functions in many dimensions can serve as proxy for landscape models, and provide a basis for the exploration of conc`eptual issues associated with landscape scenarios. here we explore the number and slope of minima as a function of the vacuum energy in an $N$-dimensional Gaussian random potential. We derive a probability density for the density of minima in $N$ dimensions, showing that after rescalings its properties are fully defined by $N$ and a single free parameter. This gives us $p(\Lambda)$, the probability density function of vacuum energies in these scenarios. \re{little more to come}}

\begin{document}

\maketitle

\section{Introduction}

Over the last two decades cosmology has developed in apparently paradoxical directions. Observationally, the rise of ``precision cosmology'' makes it possible to measure key parameters to within a few percent, setting stringent tests for the detailed evolutionary narrative given by concordance $\Lambda$CDM cosmology \cite{Planck2018,DES}. Conversely, theoretical investigations of both slow-roll inflation and string theory along with a non-zero dark energy density motivates  theoretical investigations of multiverse-like scenarios. In particular, studies of stochastic inflation \cite{Linde1986,Adshead2007} suggest that the mechanism that produces astrophysical density perturbations could also support {\em eternal inflation\/}, generating infinite numbers of  {\em pocket universes\/} \cite{Guth2001}. Likewise, studies of flux compactified string vacua points to a possible  {\em landscape\/} \cite{Susskind2003} or {\em discretuum\/} \cite{Bousso2000}   of vacua within the theory. These developments open the door to anthropic explanations of the non-zero vacuum energy density, insofar as a value that was  exactly zero could have been more plausibly explained by an unknown symmetry. 

Stochastic (or eternal) inflation implies the existence of a multiverse composed of many pocket universes, but this does not require that the ``low energy" (i.e. LHC scale) physics or vacuum energy differs between pockets:  the naive quadratic inflation model is potentially eternal, but has a unique vacuum.  By contrast, landscape models have multiple vacua which can, in principle, be populated by stochastic inflation or tunneling. The string landscape, built on the plethora of flux-stablilsed vacua that exist inside Calabi-Yau spaces, is well-known but  is not necessarily a unique realisation of this scenario. The complexity of the landscape  and the vast number of vacua it supports is the basis of its purported explanatory power: the number of vacua is almost uncountably large (e.g. $10^{500}$ or greater \cite{Douglas2003}) and any value of the vacuum energy can thus conceivably be realised within it. 
 
The detailed properties of any possible landscape are almost entirely unknown.  However, an intriguing approach to landscape scenarios is to strip them down to their barest essence -- by realising multiverse cosmology within a {\em random\/} multidimensional ($N\sim100$ or more) potential of interacting scalar fields.\footnote{Random is used here in the  context of random function theory \cite{GRF1, GRF2, GRF3}.  We refer to random functions rather than random fields, the nomenclature often seen in the mathematical literature, to avoid confusion with the individual scalar fields that are coupled by the potential.}  In this approach the ``large $N$'' properties of the multidimensional landscape actually provides leverage that can be used to develop an understanding of its properties. The first steps in this direction were taken by Aazami and Easther \cite{Aazami2006}, investigating ensembles of Hessian matrices describing extrema in a random landscape. At  a minimum in the landscape the eigenvalues of the Hessian are all positive. For simple random matrix distributions eigenvalues are likely to be evenly distributed between positive and negative values with fluctuations away from this situation being strongly suppressed at even moderate values of $N$, suggesting that the number of minima is super-exponentially smaller than the number of saddles. However, the individual entries of Hessians matrices of random functions are correlated and therefore not drawn from identical, independent distributions \cite{Battefeld2012,Easther2016}, violating a common premise of simple random matrix theory and making minima more probable that this initial analysis suggested.  This overall approach has now been widely pursued and extended in a number of directions \cite{Easther2006, Frazer2011, Henry2009, Marsh2013, Agarwal2011,Yang2012,Masoumi2016,Yamada2018}. This line of inquiry has also motivated studies of the properties of random matrices and random functions at large $N$ \cite{Bray2007,Dean2008,Majumdar2009,Bachlechner2014,Battefeld2012,Fyodorov2013,Masoumi2017}. Similar mathematical problems arise in statistical mechanics, string theory, and complex dynamics \cite{Fyodorov2004,Douglas2004,Douglas2006,Fyodorov2007,Fyodorov2012,Fyodorov2018,Ros2019}.

%The theory of inflation is the current best explanation for certain perplexing observations of the Universe, such as the monopole problem, horizon problem, and flatness problem. Inflation is thought to be caused by a scalar field, but the exact nature of this field is shrouded in unknowns. The simplest possibility is a one-dimensional scalar field analogous to the gravitational potential; however multidimensional scalar fields are also possible. In particular, string theory predicts the existence of a highly complex, $O(100)$ dimensional scalar field known as the \emph{landscape}. The string landscape is so complex that quantitative predictions are hard to extract; as a result, most studies of the landscape assume it is a Gaussian random field

In the conventional picture of the multiverse, a pocket universe traces out a path in the landscape. Regions of the landscape where the gradient of the potential in the ``downhill'' direction(s) is small will yield slow-roll inflation. If the landscape is bounded below, typical semi-classical trajectories terminate in a local minimum, whose value fixes the apparent cosmological constant. Moreover, bubbles of space can tunnel between minima, eventually populating all possible minima in the landscape.  The {\em measure problem\/} for the multiverse is notoriously complex, but in this scenario we can use the known properties of Gaussian random fields to estimate $p(\Lambda)$ -- the distribution of possible cosmological constants -- as a function of the dimensionality of the landscape.  This probability is of course distinct from the likelihood that an arbitrary observer will measure a given value of $\Lambda$ as this will be convolved with complex anthropic considerations. However, we will show that for a nontrivial volume of parameter space,  $\int_0^\infty  p(\Lambda) {\rm d}\Lambda \ll 10^{-M}$  where $M$ is a number of ${\cal{O}}(100)$, so the corresponding landscape thus possesses no metastable solutions with  positive vacuum energy. Moreover, we show that in scenarios where positive minima are expected to be extremely rare or nonexistent\SH{the ``or nonexistent'' here is confusing, because if something is non-existent how can it have a smallest second derivative. I favour just leaving it as extremely rare}, the smallest second derivatives of the potential at these rare minima will be much smaller than those found near typical minima, making these scenarios more likely to support quintessence solutions. 


\re{more on physics} 
 -- it is still unclear whether any specific stringy construction  realises  the $SU(3) \times SU(2) \times U(1)$ gauge group of the Standard Model.  More recently the Swampland Conjecture suggests that all stable minima of the theory might actually be ``underwater'' \cite{Agrawal2018},  located at negative values of $\Lambda$. If true, this would appear to require that the cosmological dark energy was underpinned by dynamical quintessence-like evolution.  


 We begin from an $N$-dimensional generalisation of the Kac-Rice formalism \cite{Kac1943,Rice1945} and the  machinery developed and summarised by Bond, Bardeen, Kaiser and Szalay  \cite{BBKS} for studying the statistics of Gaussian random functions in three dimensions. This yields $N$-dimensional integral expressions for the proportion of minima that will have a given value of the potential, $V$. At $N=2$ the full integral can be evaluated analytically; at $N \lesssim 10$ we can directly compute the full integrals numerically; and for $N \lesssim 100$ we evaluate Gaussian approximations to the underlying integrals . The Gaussian approximations are tested against the exact numerical result for $N <10$ where they match closely. These techniques can be generalised to other, more complex questions about trajectories in these potentials, and give information about the ``shapes'' of minima which may inform analyses of tunnelling and inflation. We show that $p(\Lambda)$, the probability density function for the vacuum energy, depends on the dimensionality $N$ and a single free parameter for a Gaussian random landscape, and calculate how $p(\Lambda)$ varies with $N$. \re{Eigenvalues; motivation for working numerically}. \sh{We use $V$ and $\Lambda$ interchangeably within the text to mean the same thing. Preference is given to $V$ when discussing the potential energy of the underlying field and preference is given to $\Lambda$ when discussing the probability of obtaining the vacuum energy in our universe; however ultimately these are the same quantity.}

 \SH{I've had a go at expressing our different use of $V$ and $\Lambda$. Another option would be to literally say we use them interchangeably to mean the same thing and leave it at that. I think \emph{something} needs mentioned here though so that readers know they are interchangeable without having to read the whole paper carefully.}

\section{Random Potentials in $N$ Dimensions}

%\sh{\sout{We begin by developing an $N$-dimensional analogue of the treatment of three dimensional random functions due to Bardeen, Bond, Kaiser and Szalay (henceforth BBKS) \cite{BBKS}, generalising their derivation and keeping their notation as far as possible.}}\SH{We're no longer following the notation and we say the rest in the paragraph just before this, in the introduction}.

We treat the potential energy function $V({\vec{\phi}})$ as a Gaussian random function over an $N$-dimensional field space. We wish to examine minima and saddles, therefore we require the probability density for the value of the potential itself and the values of its derivatives, $\eta_i = \partial V/\partial \phi^i$ and $\zeta_{ij}=\partial^2 V/\partial \phi^i\partial \phi^j$ at individual points in this field space. These variables can be grouped together into a vector ${\bf y} = [V,\eta,\zeta]$, with $\mathcal{N}=1+N+(N^2+N)/2$ independent components. $V$ is a Gaussian random function, therefore the variables in ${\bf y}$ are described by a multivariate Gaussian distribution. A general multivariate Gaussian distribution with $\mathcal{N}$ independent variables has the form
  %
\begin{equation} \label{MultivariateGaussian}
\begin{split}
p({\bf y})d^\mathcal{N}{\bf y} &= \frac{e^{-Q}}{[(2\pi)^\mathcal{N} \mathrm{det}(M)]^{1/2}} d^\mathcal{N}{\bf y} \, ,\\
Q &\equiv \frac{1}{2} \sum_{i,j}^\mathcal{N} \Delta y_i (M^{-1})_{ij} \Delta y_{j} \, .\\
\end{split}
\end{equation}
%
Here $\Delta y_i$ is the difference between the actual value and the mean value, i.e. $\Delta y_i \equiv y_i - \langle y_i \rangle$, and $M$ is the \emph{covariance matrix}, 
%
\begin{equation}
M_{ij} \equiv \langle \Delta y_i \Delta y_j \rangle.
\end{equation}
%
Averages denoted by $\langle \,\,\rangle$ are ensemble averages. We further assume that $\langle V\rangle = \langle \eta\rangle = \langle \zeta\rangle = 0$.\footnote{$\langle V\rangle=0$ can always be obtained by a constant shift in the definition of $V$. $\langle \eta \rangle = 0$ and $\langle \zeta\rangle = 0$ can be enforced by assuming $V$ is statistically isotropic in field space. An interesting path for future work would be to examine our results without this assumption of statistical isotropy.} Therefore the probability density only depends on the covariance matrix, $M$, and its inverse.

We next introduce the field space power spectrum, $P$, of the random function $V$, which will be useful for writing $M$ in a concise form. We define it here to be the Fourier transform of the correlation function of $V$, i.e.
%
\begin{equation}\label{powspec}
\langle V(\vec{\phi}_1) V(\vec{\phi}_2) \rangle = \xi(|\vec{\phi}_1-\vec{\phi}_2|)= \frac{1}{(2\pi)^N} \int d^Nk e^{i \vec{k} \cdot (\vec{\phi}_1-\vec{\phi}_2)} P(k).
\end{equation}
%
We have assumed $V$ is statistically homogeneous and isotropic in field space, therefore $\xi$ depends only on $|\vec{\phi}_1-\vec{\phi}_2|$ and  $P$ depends only on the magnitude of the Fourier coordinate $k$.\footnote{We work in a field space basis where the field space metric is Euclidean.} The moments of the power spectrum are defined to be
%
\begin{equation} \label{moments}
\sigma_n^2 = \frac{1}{(2\pi)^N}\int d^Nk (k^{2})^n P(k)
\end{equation}
%
This gives $\sigma_0^2=\xi(0)=\langle V^2 \rangle$.

We can differentiate equation \eqref{powspec} and then set $\vec{\phi}_1 = \vec{\phi}_2$ to get

\begin{align*}
\langle \eta_{i}\eta_{j}\rangle &= \frac{1}{(2\pi)^N} \frac{\partial}{\partial \phi_1^i}\frac{\partial}{\partial \phi_2^j} \int d^Nk e^{i \vec{k} \cdot (\vec{\phi}_1-\vec{\phi}_2)} P(k)\bigg{|}_{\vec{\phi}_1=\vec{\phi}_2}\\
&= \frac{1}{(2\pi)^N}\int d^Nk (k^i k^j) P(k)
\end{align*}
%
The integrand on the RHS is an odd function of both $k^i$ and $k^j$, therefore the integral over all $\vec{k}$ is zero unless $i=j$. Furthermore, because $k^2 = \sum_i k_i^2$,  $\sum_i \langle \eta_{i}\eta_{i}\rangle = \sigma_1^2$. We have assumed the field is statistically isotropic and thus $\langle \eta_{i}\eta_{i}\rangle=\langle \eta_{j}\eta_{j}\rangle$, meaning $\langle \eta_{i}\eta_{i}\rangle=\sigma_1^2/N$ and $\langle \eta_{i}\eta_{j}\rangle=\delta_{ij}\sigma_1^2/N$.

%\begin{align*}
%\langle \eta_{\alpha,i}\eta_{\beta,j}\rangle = K \delta_{\alpha,\beta}\delta_{ij} &\rightarrow \delta_{ij}\langle \eta_{\alpha,i}\eta_{\beta,j}\rangle = NK \delta_{\alpha,\beta}=\sigma_1^2\\
%&\rightarrow K = \frac{1}{N}\sigma_1^2
%\end{align*}

A similar analysis holds for the second derivatives $\zeta_{ij}$, and will yield the rest of the elements of the covariance matrix. In terms of the moments of the power spectrum these are:
%
\begin{equation} \label{corr}
\begin{split}
\langle VV \rangle &= \sigma_0^2 \\
\langle\eta_i\eta_j\rangle &= \frac{1}{N}\delta_{ij}\sigma_1^2 \\
\langle V\zeta_{ij}\rangle &= -\frac{1}{N}\delta_{ij}\sigma_1^2 \\
\langle\zeta_{ij}\zeta_{kl}\rangle &= \frac{1}{N(N+2)}\sigma_2^2(\delta_{ij}\delta_{kl}+\delta_{il}\delta_{jk}+\delta_{ik}\delta_{jl})
\end{split}
\end{equation}
%
and all other correlations are zero. For $N=3$ this reduces to equation A1 of \cite{BBKS} (hereafter called BBKS). 

%We define the following vector\SH{This small passage is the only time the notation $\alpha$ is used. I think we can get away without introducing it. I think in general the way BBKS goes from $F$ at different points in space to $F$, $\eta$ and $\xi$ is confusing and we can make it a bit clearer here if we want}:

%\begin{equation}
%\begin{split}
%\alpha = \{F,\eta_1,\eta_2,\ldots,\xi_{11},\xi_{22},\ldots,\xi_{NN},\xi_{N-1,N},\xi_{N-2,N},\ldots,\xi_{1N},\xi_{N-2,N-1},\\
%\ldots\xi_{1,N-1},\ldots,\xi_{12}\}
%\end{split}
%\end{equation}

%\noindent With this choice for $\alpha$ (equivalent to $\Delta y$ in Eq. \ref{MultivariateGaussian}), the covariance matrix $M_{ij}\equiv\langle\alpha_i\alpha_j\rangle$ and its inverse $K \equiv M^{-1}$ takes the following general form\SH{I guess this result comes from Mathematica? There must be a way of simplifying the $K_{\xi_{ij}\xi_{kl}}$ terms into one expression using $\delta_{ij}$ etc, like with $M$. Actually, this $K$ seems to never be used so I'm not sure we need to write it down. If we want to write out the inverse in all detail we should do it in terms of the variables we eventually use (i.e. $x_i$)}:

%\begin{align*}
%K_{F, F} &= \frac{\sigma_2^2}{\sigma_0^2\sigma_2^2-\sigma_1^4} \\
%K_{F, \xi_{ij}} &= \frac{\sigma_1^2}{\sigma_0^2\sigma_2^2-\sigma_1^4} \\
%K_{\eta_i,\eta_j} &= \frac{N}{\sigma_1^2}\\
%K_{\xi_{ii},\xi_{ii}} &=  \frac{N(N+2)}{\sigma_2^2} \\
%K_{\xi_{ij}, \xi_{ij}} &= \frac{N\sigma_0^2\sigma_2^2-(N+2)\sigma_1^4}{2(\sigma_1^4\sigma_2^2-\sigma_0^2\sigma_2^4)}, (i\neq j)\\
%K_{\xi_{ii}, \xi_{jj}} &= \frac{(N(N+1)-2)\sigma_1^4 - N(N+1)\sigma_0^2\sigma_2^2}{2(\sigma_1^4\sigma_2^2-\sigma_0^2\sigma_2^4)}, (i \neq j)\\
%\end{align*}

%\noindent and all other terms are zero\SH{Are there some $\delta_{ij}$ terms missing in the 2nd and 3rd lines above?}. The probability density of $\alpha_i$ is, from Eq. \ref{MultivariateGaussian}\SH{This is just eq. 2.2 repeated with $\alpha$ instead of $y$, I think there is a way of expressing all of this without so many introduced variables like $y$ $\alpha$ that are used only once each. I don't we've ever explicitly said we're considering functions/fields where $\langle F\rangle=0$ either, which we've assumed in order to write this equation.}.

%\begin{equation} \label{ProbDistrib}
%p(\alpha_i)=\frac{1}{(2\pi)^{N/2}\sqrt{\mathrm{det}M}} e^{-\frac{1}{2}\alpha K \alpha}
%\end{equation}
%
%We can usually ignore the constant prefactor since we will primarily be concerned with ratios of probabilities.
This covariance matrix is far from diagonal; and our analysis will be facilitated if we use a basis that is as close to diagonal as possible. The $\eta_i$ variables are already diagonal, as are the $\zeta_{ij}$ terms with $i\neq j$ but the $\zeta_{ii}$ variables are correlated to each other, and also  to $V$. We look for a set of $N$ linear combinations of these $N$ variables that is diagonal, choosing,
\begin{align}
\label{BasisTransform}
x_1 &= -\frac{1}{\sigma_2}\sum_i\zeta_{ii} \nonumber \\
x_n &= -\frac{1}{\sigma_2}\sum_{i=1}^{n-1}\left(\zeta_{ii}-\zeta_{nn}\right),\,\, (2\leq n \leq N) \, .
%\sigma_2x_3 &= -(\xi_{11}+\xi_{22}-2\xi_{33})\\
%\sigma_2x_4 &= -(\xi_{11}+\xi_{22}+\xi_{33}-3\xi_{44})\\
%\ldots
\end{align}
%
The $x_n$ here are analogous, but not identical, to BBKS's $x, y, z$. Following BBKS, we also rescale $V$, introducing $\nu = V/\sigma_0$. With this choice of basis in equation \eqref{corr} become
%
\begin{eqnarray}
  \langle\nu^2\rangle &=& 1 \nonumber\\
  \langle x_1^2\rangle&=&1 \\
  \langle\nu x_1\rangle &=& \gamma \nonumber\\
  \langle x_n^2 \rangle &=& \frac{2n(n-1)}{N(N+2)},\,\, (2\leq n \leq N) \nonumber
\end{eqnarray}
%
\noindent where $\gamma = \sigma_1^2/(\sigma_2 \sigma_0)$. The only non-diagonal correlation left is between $\nu$ and $x_1$.

The $Q$ factor in equation \eqref{MultivariateGaussian} becomes
%
\begin{equation} \label{Q}
\begin{split}
2Q = x_1^2 + \frac{(\nu-\gamma x_1)^2}{1-\gamma^2}+\sum_{n=2}^N\frac{N(N+2)}{2n(n-1)}x_n^2 + \frac{N \pmb{\eta}\cdot \pmb{\eta}}{\sigma_1^2} + \sum_{i,j;i > j}^N\frac{N(N+2)(\zeta_{ij})^2}{\sigma_2^2}
\end{split}
\end{equation}
%
This is the equivalent of BBKS equation (A4) for $N$-dimensions. Note that the first two terms remain constant for all $N$, but the remaining terms are $N$ dependent.  

Equations \eqref{Q} and \eqref{MultivariateGaussian} give, in as diagonal a form as possible, the full probability density function for the function, $V$, and its first two derivatives at an arbitrary point in field space. We are interested in characterising the distribution of \emph{minima} of $V$, and begin by looking at the number density of extrema, i.e. points where $\eta=0$. \sh{The total number of extrema in some region in field space is $N_{\rm ext} = \int {\rm d}^N\phi \, \left| {\rm det}\zeta(\phi)\right|\delta^{(N)}[\eta(\phi)]$. The integrand is a delta-function that integrates to give 1 every time a point with $\eta=0$ is passed over in field space. The additional factor $\left| {\rm det \zeta} \right|$ arises because the argument of the delta-function is $\eta$, whereas the integration variable is $\phi$. $|{\rm det}\zeta|$ is the Jacobian of the transformation between these two variables, i.e. ${\rm d}\eta_i/{\rm d}\phi_j = \zeta_{ij}$. The number \emph{density} of extrema is therefore}
%
\begin{equation}
n_{\rm ext}(\phi) \,\,{\rm d}^N \phi= |{\rm det}\,\, \zeta(\phi)| \delta^{(N)}\left[ \eta(\phi)\right] {\rm d}^N \phi.
\end{equation}

%
The number density of extrema, $n_{\rm ext}(\phi)$, is itself a random variable. However, we will work with the \emph{expected} number density, which is simply the ensemble average of $n_{\rm ext}$, or
% 
\begin{equation} \label{NumberDensity}
\langle n_{\rm ext}(\phi)  \rangle= \int |{\rm det}\,\, \zeta(\phi)| p(V,\eta=0,\zeta)d\nu d\zeta
\end{equation}
where for notational convenience we have dropped the ${\rm d}^N \phi$ from each side.

Finally, we need to restrict this integral to count the extrema that are also local minima. It is easiest to do this by considering the eigenvalues, $\lambda_i$ of the Hessian of the landscape $\zeta$ and restricting them to be positive.\footnote{Note there is an alternative convention where the eigenvalues are defined with the opposite sign, in which case \emph{negative} eigenvalues correspond to minima; e.g. Ref.~\cite{BBKS}.}  The Hessian is symmetric by definition. We can also rotate it such that it is diagonal, meaning  $\zeta_{ii}=\lambda_i$, $\zeta_{ij}=0$ and $|{\rm det} \zeta| = \prod_i |\lambda_i|$. The new integration variables are then the eigenvalues themselves and the set of rotation angles required to diagonalise $\zeta$.  In 2D and 3D, the Jacobian of this transformation can be calculated explicitly, which leads to  ${\rm d} \zeta = \prod_{i \neq j}^N |\lambda_i - \lambda_j|\left(\prod_k {\rm d}\lambda_k\right) {\rm d} \Omega$, where ``${\rm d}\Omega$'' represents the $(N^2-N)/2$-dimensional integral measure of the set of rotation angles. The same result holds in $N$ dimensions.\footnote{A proof in $N$ dimensions is given in section V of \cite{Easther2016}, generalising the 3D  BBKS result. \re{can we just say what the typos are?}\SH{The typos are inconsequential to the actual proof, so I'd favour ignoring them. Otherwise we should just reproduce the proof via Lerh's notes, although that essentially means re-writing the Easther, Guth, ?Masoumi proof out again without the typos. The best option might be for EGM to update their paper without the typos?}\lfl{It's not submitted yet, surely updating it is possible}} The function $V$ and its derivatives are statistically isotropic. Therefore each set of rotation angles is as probable as any other, and the integral over all the rotation angles must give just a constant.

We now have  the ingredients we  need, but  also enforce an ordering on the eigenvalues to avoid dealing with a multimodal integrand.  We define  $\lambda_1 \geq \lambda_2 \geq \lambda_3 \ldots \geq 0$ so our boundary conditions become $x_1\leq x_N\leq x_{N-1} ... \leq x_2 \leq 0$, and the mapping between $\lambda_i$ and $x_i$  follows from Equation~\ref{BasisTransform}. This gives significantly simpler boundary conditions than \sh{\sout{our}} earlier choices \sh{that have been used} for diagonalising the covariance matrix \SH{Previously I had a direct comparison to BBKS here. Without it this statement is a bit obscure}.

Finally we have the following expression for the expected number density of minima 
%
\begin{equation} \label{DensityOfPeaks}
\langle n_{{\rm min}} \rangle = A \int_{\lambda_1 \geq \lambda_2 \ldots \geq 0} G \times e^{-Q} \, d\nu \,d^Nx
\end{equation}
%
\noindent where $G$ has the form\footnote{$G$ can also be expressed in terms of $x_n$ using the inverse transform of Eq. \ref{BasisTransform}.}

\begin{equation}
G = \left(\prod_{i}^{N} \lambda_i \right)\left(\prod_{i<j} |\lambda_i-\lambda_j|\right),
\end{equation} 
%
$Q$ is given by Eq. \ref{Q} \sh{with $\zeta_{ij}=0$ for $i\neq j$} and the constant factor $A$ has absorbed the Jacobian for the transformation between $\lambda_i$ and $x_n$. More generally, we can view the expression
%
\begin{equation}
{\cal L}(\lambda_1,\cdots, \lambda_N; V, \gamma) = \left(\prod_{i}^{N} \lambda_i \right)\left(\prod_{i<j} |\lambda_i-\lambda_j|\right) e^{-Q}
\end{equation} 
%
as an unnormalised probability density that gives, for a fixed value of $N$, the (relative) likelihood of finding a minimum at which the landscape has potential value $V$, and the Hessian matrix has eigenvalues $\lambda_i$ as a function of the single independent variable $\gamma$. This expression is exact;  we immediately see that the prefactor to the exponential enforces a variant of {\em eigenvalue repulsion\/} \cite{Mehta1990}  in that the likelihood of finding a minimum with near-identical $\lambda_i$ is vanishingly small. 



\section{Landscape Heuristics}

Our  overall goal is to understand $p(\Lambda)$, the probability density of energy densities (ie the values of $V(\phi)$) at the minima of a Gaussian random landscape. In particular, we are interested in the proportion of  minima with $V > 0$, which is given by\footnote{We assumed earlier that $\langle V \rangle = 0$. In principle, one could consider an ``offset'' landscape, consisting of a Gaussian random field with zero mean, plus a constant, such that $\langle V \rangle \neq 0$ but we do not explore this here.}
\begin{equation} \label{PminIntegral}
  P(\Lambda >0| N,\gamma) =  \frac{\int^\infty_0 \,\,d\nu \int_{\lambda_1 \geq \lambda_2 \ldots \geq 0} d^Nx \,\, G \times e^{-Q} }{\int^\infty_{-\infty} d\nu \int_{\lambda_1 \geq \lambda_2 \ldots \geq 0} d^Nx\,\,G \times e^{-Q}}
  \end{equation}
 %
 and any specific $p(\Lambda)$ can be computed by dropping the integral over $\nu$ and setting $\nu=\Lambda/\sigma_0$ in the numerator.  
 %
%
This integral depends on the value of $Q$ (Eq. \ref{Q}) and therefore on the moments of the power spectrum $\sigma_0, \sigma_1$,  and $\sigma_2$, through the single parameter $\gamma$. The allowed range of this variable is $0<\gamma<1$ because $0<\sigma_1^2<\sigma_0\sigma_2$.\footnote{See Section \ref{Proof} for a proof.}


Broadly speaking, the overall distribution $p(\Lambda | N,\gamma)$ moves to lower values as $N$ and $\gamma$ are increased;  representative results for moderate $N$ are shown in Figure~\ref{distributions}. Moreover, as $\gamma$ increases, the width of the distribution contracts. Consequently, we will find that when $\gamma$ is close to unity and $N \gtrsim {\cal{O}}(10^2)$, $P(\Lambda >0)$ can be almost arbitrarily small, as we quantify below. 


\begin{figure}
  \centering
  \includegraphics[width=0.45 \linewidth]{PLam_gamma.eps}  \hfill
  \includegraphics[width=0.45 \linewidth]{PLam_N.eps}
  \caption{[Left] $p(\Lambda)$ for $\gamma = 0.2$, $0.5$ and $0.8$ and [Right] $p(\Lambda)$ for $N=3$, $5$ and $8$. The distribution moves leftward with increasing $N$ and increasing $\gamma$. The results were obtained by numerically evaluating the full $x_n$ integrals to obtain $p(\Lambda)$. \SH{Change y-axis label to $p(\Lambda)$} }
  \label{distributions}
  \end{figure}

  % def of gamma, and power spectrum
  \SH{I don't think the below is clear and entirely correct. The crucial thing for what decides the value of $\gamma$ is the balance between $\sigma_1^2$ and $\sigma_2$. You can see this as $\gamma \sim \langle k^2\rangle/\langle k^4\rangle^{1/2}$. In other words if you treat $P(k)$ as a sort of probability, or weighting, in $k$ space, then $1/\gamma$ measures a kind of normalised variance of $k^2$. If $P(k)$ is wider, then the ``variance'' of $k^2$ increases and $\gamma$ shrinks. Explaining this rigorously would be a bit laboured. I'm OK with us just asserting that a wider range of scales corresponds to a smaller $\gamma$ (I prefer just asserting), but if we try to explain it we need to be clear and correct. (i.e. it is true that $\sigma_2$ increases if $P(k)$ is non-trivial over a wider range of scales, but so does $\sigma_1^2$, so it isn't immediately obvious that $\gamma$ should decrease.) I won't edit until we make a decision...}
This dependence on $\gamma$ and $N$ can be understood qualitatively via the expressions for $\sigma_2$ for the probability density. Via its definition, $\sigma_2$ increases as the range of $k$ over which the spectrum $P(k)$  is nontrivial  increases, and $\gamma$ will correspondingly decrease. Conversely, when $\gamma$ is close to unity, the power spectrum is peaked over a small range of $k$ and the random function is dominated by modes with a narrow band of wavelengths.  At small $\gamma$ the spectrum of $V(\phi)$ thus has power over a wide range of scales. This points to the presence of significant ``ripples'' on top of  larger-scale structure in $V(\phi)$, which  produce local minima even $V(\phi)$ is relatively large,  as illustrated in Fig~\ref{examples1}.  Similarly, while the second derivatives of a random function are correlated, at values of $V$ large enough for minima are rare, increasing $N$  increases the number of directions that must have an unlikely value of $\zeta_{ii}$. 

We can likewise see $N$-dependence semi-quantitatively by noting that the number of terms in the polynomial $G$ grows rapidly with $N$, so the full probability density at minima prefers larger magnitude eigenvalues, $|\lambda_i|$. Since $x_1$ is the sum of the eigenvalues, as its magnitude grows the $(x_1-\gamma \nu)^2$ term in $Q$ also grows. For minima, $x_1<0$, therefore large $|x_1|$ makes it less likely to find minima with $\nu >0$ (or $\nu <0 $ for maxima).  Note that at a generic point in field space $\langle x_1^2\rangle = 1$; however at a minimum $\langle x_1^2 \rangle >1$ due to the effect of $G$.   


\begin{figure}
  \centering
    \includegraphics[width=\linewidth]{TwoSigmas.png}
  \caption{Illustrative realisations of 1D functions. The left figure has a small $\gamma$ and power over a greater range of scales, allowing minima (maxima) to appear in significant numbers above (below) zero. When $\gamma$ is large (right figure) the spectrum is dominated by a smaller range of modes, and most minima are low-lying.}
  \label{examples1}
\end{figure}

 % integrals over V
\SH{This specific paragraph feels like it belongs in the next section now} We can perform the integrals over $\nu$ in Eq. \ref{PminIntegral} analytically. The only dependence of the integrand on $\nu$ is via the first two terms of $Q$, which are independent of $N$. Consequently, we can write the denominator of Eq. \ref{PminIntegral} as 
%
\begin{eqnarray}
\nonumber {\rm denom} &=&
\int^\infty_{-\infty} d\nu \int_{\lambda_1 \geq \lambda_2 \ldots \geq 0} d^Nx \,\,G \times e^{-Q} \\ 
\nonumber &=&  \int d^Nx\,\, f(x_1,x_2 \ldots )  \int^\infty_{-\infty} d\nu \,\exp\left(-\frac{(\nu- \gamma x_1)^2}{2(1-\gamma^2)}\right)\\
&=& \sqrt{2\pi (1-\gamma^2)}  \int d^N x \,\, f(x_1,x_2 \ldots )
\end{eqnarray}
%
with
%
\begin{equation} f(x_1,x_2 \ldots ) =  G\times \exp\left(-\frac{x_1^2}{2}-\sum_{n=2}^N\frac{N(N+2)}{4n(n-1)}x_n^2 \right).
\end{equation}
% 
Similarly, the $\nu$ integral in the numerator can be performed to yield an error function
%
\begin{eqnarray}
\nonumber {\rm numer} &=&
\int^\infty_{0} d\nu \int_{\lambda_1 \geq \lambda_2 \ldots \geq 0}d^N x\,\, G \times e^{-Q} \\ 
&=& \sqrt{\frac{\pi (1-\gamma^2)}{2}}  \int d^N x \,\, f(x_1,x_2 \ldots )\times \left(1+{\rm erf}\left(\frac{\gamma x_1 \sqrt{1-\gamma^2}}{\sqrt{2}}\right) \right)\,\, .
\end{eqnarray}
%
\sh{\sout{However, the general expressions are intractable. }}
%
%\begin{figure}
%  \centering
%    \includegraphics[width=\linewidth]{PVaryingWithN.png}
%  \caption{A plot showing the value of $P(V>0|{\rm min})$ as a function of $N$ with $N\le10$, for $\gamma$ values $\frac{1}{5}, \frac{1}{3.5}$ and $\frac{1}{2}$ from top to bottom.\SH{Title needs changed}}
%  \label{gamma}
%\end{figure}

 
\SH{This one still belongs here though}Given the dependence of $p(\Lambda|N,\gamma)$ on $N$ and $\gamma$ it is clear that as these variables increase $P(\Lambda>0|N,\gamma)$ will involve the increasingly rare tail of an increasingly narrow distribution. Figure~\ref{N6} shows $P(\Lambda>0|N,\gamma)$ as a function of $\gamma$ for values of $N$ that are small enough for the relevant integrals to be evaluated numerically, and we see that positive minima grow far less likely as $N$ and $\gamma$ increase. 



\begin{figure}
  \centering
  \includegraphics[width=.6 \linewidth]{N369.eps}
  \caption{The probability that a given minimum has $V > 0$ as a function of $\gamma$, for $N=3, 6, 9$. We see that all the heuristics are obeyed: the probability decreases with $N$, and  $\gamma$.\SH{y-axis label changed to $P(\Lambda>0|N,\gamma)$}}
  \label{N6}
  \end{figure}


\section{Gaussian Landscapes: Evaluating $P(\Lambda)$} \label{PeakNumbers}

\SH{mostly good, want to frame it though as three different integrals being estimated. The $V$ ones, the denom ones and the numer ones. Each is done identically, but for slightly different integrand functions. Not sure if we want to plot P(Lam) or just ratio of numer or denom to exact integral? If we do plot P(Lam) I think we should plot corrected P(Lam) to show how awesome the fit can be. We also should incclude here or in an appendix the $\alpha^{N-1}$ stuff}
  
  We now turn to the problem of evaluating $p(\Lambda|N,\gamma)$  for more general parameter values. Many and perhaps all of the following calculations could be performed using analytical techniques in a large-$N$ limit. However,  as we are particularly interested in scenarios involving extreme tails of  the probability distribution we will focus on quasi-numerical strategies for obtaining quantities of interest. Moreover, we are  not necessarily working at ``large'' $N$; given the inherently speculative nature of this investigation, there are few  grounds for specifying likely values of $N$;  $N\sim{\cal O}(10^2)$ is not unreasonable, but we cannot necessarily rely on results that may only hold well as $N\rightarrow \infty$. 

That said, for $N>10$, direct calculation becomes very resource-intensive. To proceed, we approximate the full integrand as a Gaussian; fixing $\gamma$ and find the values of $x_n$ that maximize the integrand in Eq. \ref{DensityOfPeaks}, or 
%
\begin{align*}
\begin{split}
\langle n_{\rm min}(\nu)\rangle d\nu &=A\int_{\lambda_1 \geq \lambda_2 \geq \lambda_3 \ldots \geq 0} e^{\mathrm{log}G-Q} \prod_n dx_n d\nu\\
&\approx \int_{-\infty}^{\infty} \exp\left(-\frac{1}{2}\sum_{l,m}x_lH_{lm}x_m\right)  \prod_n dx_n d\nu \\
&= \sqrt{\frac{(2\pi)^N}{\mathrm{det} H(\nu)}}d\nu
\end{split}
\end{align*}
%
\noindent where $H_{lm}$ is the Hessian of the integrand with respect to the $x_n$ variables at the peak.
\begin{figure} 
  \centering
  \includegraphics[width=.3 \linewidth]{PLam_approx.eps} \hfill
   \includegraphics[width=.3 \linewidth]{PLam_approx_log.eps} \hfill
    \includegraphics[width=.3 \linewidth]{PLam_ratio.eps}
  \caption{  
  A comparison of the unnormalised exact $p(\Lambda)$ with the Gaussian approximation, for $\gamma=0.6$ and $N=4$. The left and middle plots show the exact result and the Gaussian approximation, on linear and logarithmic axes; the ratio of the two is show on the right. The Gaussian approximation always  over-estimates the integral, but the ratio is roughly independent of $\Lambda$ and remains close to unity. }
  \label{Comparison}
\end{figure}

It turns out that the numerical location of the peak can be obtained fairly simply for $N\lesssim 200$, which will be sufficient for our purposes.\footnote{All numerical results in this paper are obtained using Mathematica. We note that the computational efficiency of the calculations can depend strongly on apparently small tweaks in their implementation.} A representative comparison between the Gaussian approximation and the exactly evaluated integral is shown in Figure~\ref{Comparison}, and we see that it is sufficiently accurate for our purposes. In particular, for fixed $N$ and $\gamma$ the discrepancy between the exact result and the approximation depends very weakly on $\Lambda$, so  the normalised results will be highly accurate.  
\SH{We could include here the comparison to $(N-1)^\alpha$ to show we understand why the gaussian approximation misses. We could also use the $(N-1)^\alpha$ corrected Gaussian approximation as the default if we want. Finally, I think we could do with a more thorough examination of when/where this approximation works and where it doesn't, as a function of $N$ and $\gamma$.} \re{include to agree  this could use more discussion, but not to go overboard} 

\begin{figure} 
  \centering
  \includegraphics[width=.6 \linewidth]{pwithN.eps}
  \caption{The probability that a given minimum has $\Lambda>0$, as a function of $N$ for $\gamma=0.2$, $0.5$, $0.8$ and $0.9$ (top to bottom) calculated using the Gaussian approximation. }
  \label{PVaryingWithNGaussian}
\end{figure}
  
In  Figure~\ref{PVaryingWithNGaussian} we show $P(\Lambda>0|N,\gamma)$ as a function of $N$ for several values of $\gamma$, given by Equation~\ref{PminIntegral}. We use the Gaussian approximation for the integrals over the $x_i$; in the numerator we compute the final integral over $\nu$ by evaluating at multiple, evenly spaced values of $\nu > 0$  and then performing a simple numerical integral. We see that the logarithms of $P(\Lambda>0|N,\gamma)$ are linear with $N$, but the constant of proportionality increases rapidly as $\gamma$ approaches unity; for $N=30$ and $\gamma = .9$ only 1 in $10^{50}$ minima in the landscape will have a positive cosmological constant. 

In practice, when $\Lambda>0$ is effectively in the right-hand tail of $p(\Lambda)$,  the value of $p(\Lambda=0|N,\gamma)$ is a reliable proxy for $P(\Lambda>0|N,\gamma)$. In the tail of the distribution,  $p(\Lambda|N,\gamma)$ will decrease significantly between $\nu=0$ and $\nu=1$, so $p(\Lambda=0|N,\gamma)$ will always overestimate $P(\Lambda>0|N,\gamma)$. However, because we have normalised $\nu$, the factor between the $\Lambda=0$ and $\Lambda>0$ case will not depend strongly on $N$ or $\gamma$ and is typically less than a factor of $10$. In other circumstances this would be a poor approximation, but here our focus is effectively on the logarithms of very small numbers, so this factor can be safely ignored. 

\begin{figure} 
  \centering
  \includegraphics[width=.6 \linewidth]{histo.eps}
  \caption{We plot $\log_{10}(p(\Lambda=0|N,\gamma))$ as a function of $N$ and $\gamma$; as $N$ becomes moderately large, less than 1 in $10^{-500}$ minima have $\Lambda>0$, for $\gamma$  close to unity.  }
  \label{fullcontourplot}
\end{figure}

Figure~\ref{fullcontourplot} displays  $p(\Lambda =0 |N,\gamma)$ as a function of $N$ and $\gamma$.  \re{out to $N=200$} \lfl{Do we want to zoom in on the region $\gamma > 0.9$?}


\section{Eigenvalue Distributions and Slopes} 

In order to compute the Gaussian  approximations to the integrals in Equation~\ref{PminIntegral} we must first locate the position of the peak as a function of the $x_i$. However, this calculation yields much more information than just $p(\Lambda  |N,\gamma)$, as the $x_i$ are a linear combination of the $\lambda_i$, the eigenvalues of the Hessian matrix of $V(\phi)$ at the minima. In particular, because we work with the full probability distribution function rather than an approximation, we can compute the likely shape of minima that occur at values of $V(\phi)$ that  are  far from the peak of $p(\Lambda)$ as easily as we can for typical values.  

\begin{figure} 
  \centering
  \includegraphics[width=.9\linewidth]{eign.eps}
  \caption{We show the expected minimum and maximum eigenvalues of the Hessian at a metastable vacuum in the landscape, as a function of $N$ for four values of $\gamma$.  Dashed lines denote eigenvalues at the most likely value of $\Lambda$; solid lines indicate values at $V=0$. The expected values of the smallest eigenvalue decreases as $N$ increases, while the maximum value is roughly unchanged. }
  \label{eigen}
\end{figure}

The range of the eigenvalue distributions is shown in Figure~\ref{eigen}. The eigenvalue distribution at the peak value of $\Lambda$ for a given $N$ is independent of $\gamma$. This can be seen by looking at the overall probability density; it is maximised with respect to $\nu$ when $\nu = \gamma x_1$; enforcing this eliminates $\gamma$ from the full  probability density.     Given that we have set $\sigma_0 = \sigma_1=1$, our potentials are effectively dimensionless, and we see that in all cases the largest eigevalue is a little less than unity. Conversely, as $N$ increases the smallest eigenvalue approaches zero. When $\gamma$ approaches unity, almost all of the minima in the landscape  occur at negative values of $\Lambda$ the relative handful of minima above the waterline become more ``elongated'' as the lowest-lying eigenvalue approaches zero. This will have implications for quintessence scenarios in any landscape, as it points to a mechanism for producing minima which are almost guaranteed to have a handful of very gradual approaches, as we discuss in the following Section. 

\begin{figure} 
  \centering
  \includegraphics[width=.45\linewidth]{h1_100.eps} \hfill \includegraphics[width=.45\linewidth]{h2_100.eps}
  \caption{The expected eigenvalue distributions are plotted for $\gamma=0.9$ and $N=100$; the left hand histogram shows the distribution at the most likely value of $\Lambda$; the right hand plot shows the result for $\Lambda=0$.}
  \label{eigendist}
\end{figure}

\begin{figure} 
  \centering
  \includegraphics[width=.45\linewidth]{l1_100.eps} \hfill \includegraphics[width=.45\linewidth]{l2_100.eps}
  \caption{The expected eigenvalues are plotted for $\gamma=0.9$ and $N=100$; the left hand plot shows the most likely value of each of the 100 $\lambda_i$; the right hand plot shows the smallest eigenvalues on a log scale. The upper points correspond to the value for $\Lambda$ for which $p(\Lambda| N,\gamma)$  is peaked; the lower points correspond to $\Lambda=0$. }
  \label{eigendist}
\end{figure}



We can also examine the distribution of eigenvalues. At  $N\gtrsim 100$ the eigenvalue distribution at the peak value of $\Lambda$ is roughly ``semicircular''; for values of $N$ and $\gamma$ for which $p(\Lambda|N,\gamma)$ is very small at zero the number of low-lying eigenvalues grows substantially. \re{does this look reminiscent of the Yamada and Vilenkin paper?} \lfl{Yes? Yamada \& Vilenkin Fig 9 shows that at large $N$, small values of the eigenvalue become more likely, although the \emph{really} small ones are unlikely} Intuitively, this makes sense, at values of $\Lambda$ for which minima are rare, we would expect that they will become increasingly ``marginal'' and the smaller the eigenvalues of the Hessian of $V(\phi)$ become, the shallower the resulting minima become. 

\begin{figure} 
  \centering
  \includegraphics[width=.6\linewidth]{ratio.eps}  
  \caption{The expected ratio of the two smallest eigenvalues is plotted as a function of $N$.   From bottom to top the lines are i) the eigenvalues at the peak  of the distribution (which do not depend on $\gamma$), and $\Lambda=0$ for $\gamma =0.5$ and $0.9$.}
  \label{ratio}
\end{figure}

Conversely, as we show in Figure~\ref{ratio} the ratio between the two lowest lying eigenvalues at a minimum increases slowly with $N$ and with $\gamma$; interestingly, not only does the value of the lowest lying eigenvalue decrease as  $N$ increases, the ratio between this and the next smallest eigenvalue increases with $\gamma$, which will have implications for cosmological models that are based on dynamical scalar fields in a landscape. 





 
\section{Discuss and Implications for Multiverse Cosmology}

In the preceding sections, we have  written down an explicit and tractable probability distribution function for an $N$-dimensional  Gaussian random function, and 

\SH{Has any paper pointed out that $P(V>0|{\rm min})$ is actually really small in the first place, maybe that itself isn't understood yet. And then we say exactly how small, and find the range of $N$ and $\gamma$ for which it is big enough that at least one above water minima is expected. We could also put the dimensions back in for $V$ (e.g. make $\sigma_0$ equal to the Planck vacuum energy)  and say something about how probable/improbable it is that $V$ gets to the value we observe?} \lfl{I'm for doing this}

\SH{For ``future work'' we could also mention that we aren't necessarily in a minimum, we're just at a point where $\eta$ is below some threshold, which would require a slightly different analysis, in particular we wouldn't limit ourselves to extrema and thus would lose the $\prod |\lambda|$ term in the pdf, thus favouring smaller eigenvalues a lot more. There's heaps of things that could be explored/asked about...} \lfl{If we're not at a minimum but rather a near-minimum with small $\eta$'s, wouldn't we be inflating?}


We have presented results for the statistics of stationary points at a given function value as a function of $N$ and $\sigma_2$. The numbers confirm the intuitive expectation that the probability of a given extremum with $V > 0$ being a minimum decreases as $N$ increases or as $\sigma_2$ decreases. We are able to calculate precise values for the probability up to $N=10$. Above this dimension, evaluating Eq. \ref{DensityOfPeaks} is computationally prohibitive, but we find that Eq. \ref{DensityOfPeaks} is well-approximated by a Gaussian integral. Using this approximation, we are able to estimate the probability up to $N \approx 30$. For $N>30$, we use only the $\nu=0$ point, which although much smaller than the actual results, remains in roughly constant ratio with it. The final probability as a function of $N$ is well-approximated by a straight line when plotted on a logarithmic scale for various values of $\sigma_2$ (Fig. \ref{PVaryingWithNGaussian}). If this trend holds to larger values of $N$, we estimate that the value of $\sigma_2$ for which $P(V>0|{\rm min})$ drops to $\sim 10^{-500}$ is approximately $1.08$.

The results of this paper establish the number of vacua that could correspond to our universe in string theory, but does not treat the distribution of eigenvalues -- and accordingly the duration of slow-roll inflation -- that could arise from these vacua. An analysis of this will be the focus of future work.

\section{Appendix}
%\subsection{Density of peaks for $N=4$} 
%For $N=4$, the full result of the integral Eq. \ref{DensityOfPeaks} is: \lfl{This needs to be re-checked, there shouldn't be $x$ in the result. Computer is busy with the $N=100$ calculations for $\sigma_2=1.08$, will do it later.}
%
%\begin{equation}
%\begin{split}
%N = \frac{1}{214990848} \mathrm{Exp}\frac{9x^2\sigma_1^4 + 2\nu x \sigma_0 \sigma_1^2 \sigma_2 - (v^2+10x^2)\sigma_0^2\sigma_2^2}{-2\sigma_1^4+2\sigma_0^2\sigma_2^2}\\\bigg{(}80x - 1610e^{3x^2}+128x^3+418e^{3x^2}x^3+4e^{4x^2}\sqrt{\pi}(3+48x^2+64x^4)\mathrm{Erf}\bigg{[}\sqrt{\frac{3}{2}}x\bigg{]}\\
%-486e^{\frac{9x^2}{2}}\sqrt{6\pi}x^2\mathrm{Erf}\bigg{[}\sqrt{\frac{3}{2}}x\bigg{]}+81e^{\frac{9x^2}{2}}\sqrt{6\pi}x^4\mathrm{Erf}\bigg{[}\sqrt{\frac{3}{2}}x\bigg{]}\bigg{)}
%\end{split}
%\end{equation}
%
%The higher-dimensional results take the same form: an overall exponential multiplied by a product of polynomials and error functions; however they are massive (for example, in 5D there are some eight hundred terms).

\subsection{$p(V|s.p.)$ for $N=2$}
\lfl{As long as the reference above to the difference with Yamada \& Vilenkin is commented out, this appendix isn't needed either}
The full expression for $p(V|s.p.)$ in 2D is:

\begin{equation}
\begin{split}
p(V|s.p.)=\frac{\sqrt{\pi}}{4\sqrt{4\gamma^2-6}}\bigg{[}\mathrm{Exp}\frac{V^2}{2(\gamma^2-1)}\bigg{(}2\mathrm{Exp}\bigg{(}\frac{V^2\gamma^2}{e^6-10\gamma^2+4\gamma^4}\bigg{)}\sqrt{\gamma^2-1}\\
-\mathrm{Exp}\bigg{(}\frac{V^2\gamma^2}{2-2\gamma^2}\bigg{)}(V^2-1)(\gamma^2-1)\gamma^2\sqrt{\frac{2\gamma^2-3}{1-\gamma^2}}\bigg{)}\bigg{]}
\end{split}
\end{equation}

\noindent where $\gamma = \sigma_1^2/\sigma_0\sigma_2$. This result can be derived using a similar method as to derive Eq. \ref{DensityOfPeaks}, but by relaxing the requirement that the smallest eigenvalue is greater than zero.

\subsection{Proof that $0 < \sigma_1^2 < \sigma_0\sigma_2$} \label{Proof}

Consider the expression:

\begin{equation}
\int (k^2 - \frac{\sigma_1^2}{\sigma_0^2})^2 P(k) dk
\end{equation}

\noindent We must have that this expression is greater than 0, because the integrand is positive. Expanding the square leads to

\begin{equation}
\begin{split}
\int k^4 P(k) dk &- 2 \int k^2 \frac{\sigma_1^2}{\sigma_0^2}k^2 P(k) dk + \int \frac{\sigma_1^4}{\sigma_0^4} P(k) dk \\
&= \sigma_2^2 - 2 \frac{\sigma_1^4}{\sigma_0^2} + \frac{\sigma_1^4}{\sigma_0^2} \\
&= \sigma_2^2 - \frac{\sigma_1^4}{\sigma_0^2} > 0
\end{split}
\end{equation}
where the second line follows from the definition of the $\sigma$'s.

Q.E.D.

\begin{thebibliography}{99}
\bibitem{Planck2018} Planck Collaboration 2018 results. Submitted to \emph{Astronomy \& Astrophysics}.
\bibitem{DES} Dark Energy Survey year 1 results. arXiv:1802.05257
\bibitem{Linde1986} A. D. Linde, Phys. Lett. B 175, 4, 395--400, 1986
\bibitem{Adshead2007} P. Adshead, R. Easther, and E. A. Lim, Phys. Rev. D 79, 063504, 2009
\bibitem{Guth2001} A. Guth, arXiv: astro-ph/0101507
\bibitem{Susskind2003} L. Susskind, arXiv:hep-th/0302219
\bibitem{Bousso2000} R. Bousso and J. Polchinski, Journal of High Energy Physics, 06, 006, 2000
\bibitem{Agrawal2018} P. Agrawal, G. Obied, P. J. Steinhardt, C. Vafa, Physics Letters B, 784, 271--276, 2018
\bibitem{GRF1} A. Masoumi, A. Vilenkin and M. Yamada, Journal of Cosmology and Astroparticle Physics, 05:053, 2017
\bibitem{GRF2} A. Masoumi, A. Vilenkin and M. Yamada, Journal of Cosmology and Astroparticle Physics, 12:035, 2017
\bibitem{GRF3} T. Bjorkmo and M.C.D. Marsh, Journal of Cosmology and Astroparticle Physics, 02:037, 2018
\bibitem{Aazami2006} A. Aazami and R. Easther, Journal of Cosmology and Astroparticle Physics (0603:013), 2006
\bibitem{Bray2007} A. J. Bray and D. S. Dean, Physical Review Letters, 98, 150201, 2007
\bibitem{Easther2006} R. Easther and L. McAllister, Journal of Cosmology and Astroparticle Physics 05:018, 2006
\bibitem{Frazer2011} J. Frazer and A. R. Liddle, Journal of Cosmology and Astroparticle Physics 02:026, 2011
\bibitem{Henry2009} S.-H. Henry Tye, J. J. Xu and Y. Zhang, Journal of Cosmology and Astroparticle Physics 04:018, 2009
\bibitem{Marsh2013} M.C.D. Marsh, L. McAllister, E. Pajer and T. Wrase, Journal of Cosmology and Astroparticle Physics 11:040, 2013
\bibitem{Agarwal2011} N. Agarwal, R. Bean, L. McAllister and G. Xu, Journal of Cosmology and Astroparticle Physics 09:002, 2011
\bibitem{Yang2012} I.S. Yang, Physical Review D, 86, 103537, 2012
\bibitem{Masoumi2016} A. Masoumi and A. Vilenkin, Journal of Cosmology and Astroparticle Physics 03:054, 2016
\bibitem{Yamada2018} M. Yamada and A. Vilenkin, Journal of High Energy Physics 2018: 29, 2018
\bibitem{Fyodorov2004} Y. V. Fyodorov, Physical Revew Letters, 92, 240601, 2004
\bibitem{Douglas2004} M. R. Douglas, B. Shiffman and S. Zelditch, Communications in Mathematical Physics, 252, 325, 2004
\bibitem{Douglas2006} M. R. Douglas, B. Shiffman and S. Zelditch, Communications in Mathematical Physics, 265, 617, 2006 
\bibitem{Fyodorov2007} Y. V. Fyodorov and I. Williams, Journal of Statistical Physics, 129, 5, 2007
\bibitem{Fyodorov2012} Y. V. Fyodorov and C. Nadal, Physical Review Letters, 109, 167203, 2012
\bibitem{Fyodorov2018} Y. V. Fyodorov, P. L. Doussal, A. Rosso, C. Texier, Annals of Physics, 397, 2018
\bibitem{Ros2019}  V. Ros, G. B. Arous, G. Biroli and C. Cammarota, Physical Review X 9, 011003
\bibitem{Dean2008} D. S. Dean and S. N. Majumdar, Physical Review E., 77, 041108, 2008
\bibitem{Majumdar2009} S. N. Majumdar, C. Nadal, A. Scardicchio, and P. Vivo., Physical Review Letters, 103, 220603, 2009
\bibitem{Bachlechner2014} T.C. Bachlechner, Journal of High Energy Physics, 2014: 54, 2014
\bibitem{Battefeld2012} D. Battefeld, T. Battefeld, S. Schulz, Journal of Cosmology and Astroparticle Physics, 06:034, 2012
\bibitem{Fyodorov2013} Y. V. Fyodorov, Markov Processes Relat. Fields, 21, 483--51, 2015
\bibitem{Masoumi2017} A. Masoumi, M. Yamada and A. Vilenkin, Journal of Cosmology and Astroparticle Physics, 07:003, 2017
\bibitem{Easther2016} R. Easther, A. Guth and A. Masoumi, arXiv:1612.05224, 2016
\bibitem{Mehta1990} M. L. Mehta, \emph{Random Matrices - 2nd edition} (Academic Press, Bolton, 1990)
\bibitem{Kac1943} M. Kac, \emph{Bull. Amer. Math. Soc.}, 43, 314320, 1943
\bibitem{Rice1945}  S. O. Rice, \emph{Bell System Tech. J.}, 24, 46--156, 1945
\bibitem{BBKS} J. M. Bardeen, J. R. Bond, N. Kaiser, and A. S. Szalay, Astrophysical Journal, Astrophysical Journal, vol. 304, page 15-61, 1986
\bibitem{Goldstein} See e.g. H. Goldstein, C. P. Poole, and J. L. Safko, \emph{Classical Mechanics 3rd ed.}, Pearson, 2001
\bibitem{VEGAS} G. P. Lepage, Journal of Computational Physics 27, 192, 1978.
\bibitem{GSL} B. Gough, \emph{GNU Scientific Library Reference Manual - Third Edition} (Network Theory Ltd., 2009)
\bibitem{Douglas2003} M. R. Douglas, Journal of High Energy Physics, 05:046, 2003
\end{thebibliography}

\end{document}
